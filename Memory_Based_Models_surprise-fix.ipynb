{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using surprise \n",
    "- Read data\n",
    "- Build basic user or item based models\n",
    "- Grid Search \n",
    "- Top N users or items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c conda-forge scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import surprise\n",
    "\n",
    "# data_dir=\"E:\\\\Work\\\\Machine Learning Course\\\\Python\\\\Module 7 Reccomendation Engines\\\\Data\"\n",
    "# os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now first I will demonstrate how we can read data on our system inside Python such that surprise is able to use the dataset to build various kinds of recommendation engines. Now broadly there are two ways to read dataframes inside surprise. \n",
    "\n",
    "One is to first create a dataframe using pandas, clean it, manipulate it and then convert the dataframe into an object that surprise would understand. \n",
    "\n",
    "The second is to directly read data from a text file into surprise. For that to happen we’ll have to make sure that our text file is in a specific format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I’ll demonstrate how we can read data from a dataframe. Below I am reading a CSV file as a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  rating  item\n",
       "0     1       2     1\n",
       "1     2       2     1\n",
       "2     3       3     2\n",
       "3     4       3     2\n",
       "4     5       1     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To read a file using surprise, one needs to make sure that data is in a specific format, there are two common ways to read a dataset, to be used in the library\n",
    "# Reading from dataframe\n",
    "# Reading from a text file\n",
    "\n",
    "# Reading data from a dataframe\n",
    "df=pd.read_csv(\"sample_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this file contains userIDs, their ratings for different item IDs. \n",
    "\n",
    "Now to convert this dataframe into an object that surprise would understand, I will need to create a reader object which I am doing below using the reader method within the surprise module. \n",
    "\n",
    "I first need to specify line format. This is nothing but specifying the sequence in which the user ID, the rating and the item IDs occur. \n",
    "\n",
    "Now in my raw dataframe you can see that the first column is of user IDs, the second column is of ratings and the third column is of item IDs.\n",
    "\n",
    "And also I know that my data is on a scale of 1 to 5, the ratings have been done on a scale of 1 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise expects data to have three columns, user, rating and item. The spelling of these columns names should be as given. If your dataframe has other columns or column names are differen, remember to change them before trying to reading them in surprise\n",
    "\n",
    "# We will need to create a reader object before we can load our dataframe into surprise \n",
    "reader=surprise.dataset.Reader(line_format='user rating item',rating_scale=(1,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I create the reader object, then I will use the load from dataframe method within the surprise library to convert this dataframe into an object that surprise will be able to build different recommendation engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=surprise.dataset.Dataset.load_from_df(df,reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this object I have an attribute called raw_ratings. This object is just a list of tuples which contain this particular data now in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 1.0, None),\n",
       " (2, 2, 1.0, None),\n",
       " (3, 3, 2.0, None),\n",
       " (4, 3, 2.0, None),\n",
       " (5, 1, 1.0, None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.raw_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also read data directly from a text file. Now for this to work we need to make sure that our text file is in a specific format. \n",
    "\n",
    "Take a look at a raw text file (open and show). \n",
    "\n",
    "Now you can see that the first row is nothing but a row of column labels. Then I have user IDs, I have their ratings on a scale of 1 to 5, I have their item IDs which is what I am specifying in this reader object. \n",
    "\n",
    "I am specifying the line format. Now since this is a csv file, the separator is a comma, the rating scale is on 1 to 5. I am skipping the first line because the first line is just the name of the columns, it doesn’t really contain my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can load the dataset from a text file as well, directly, just make sure the text file \n",
    "# has three columns named as user, rating and item\n",
    "reader=surprise.dataset.Reader(line_format='user rating item',sep=\",\", \n",
    "                               rating_scale=(1,5),skip_lines=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the reader object is created, I will use the load from file method to load data from the csv file based on the metadata stored in this reader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=surprise.dataset.Dataset.load_from_file(\"sample_data.csv\",reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I can again take a look at raw ratings which is nothing but my original data, now is in this form which is just the list of various tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '1', 2.0, None),\n",
       " ('2', '1', 2.0, None),\n",
       " ('3', '2', 3.0, None),\n",
       " ('4', '2', 3.0, None),\n",
       " ('5', '1', 1.0, None)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.raw_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s work on a slightly bigger dataset. For that I am changing my current working directory to this directory on my system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's now, work with a slightly larger dataset and train memory based collaborative filtering models\n",
    "data_dir=r\"C:\\Users\\VK\\Documents\\Poojastuff\\dono\\Manipal-Deloitte\\MachineLearning\\RecommendationSystems\\ml-latest-small\"\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And within this directory I have a file called ratings.csv, so I am reading that file first as a pandas dataframe and then I will printout the first few observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1       31     2.5  1260759144\n",
      "1       1     1029     3.0  1260759179\n",
      "2       1     1061     3.0  1260759182\n",
      "3       1     1129     2.0  1260759185\n",
      "4       1     1172     4.0  1260759205\n"
     ]
    }
   ],
   "source": [
    "mr=pd.read_csv(\"ratings.csv\")\n",
    "print(mr.head())\n",
    "mr.drop('timestamp',axis=1,inplace=True)\n",
    "mr.rename(columns={'userId':'user','movieId':'item','rating':'rating'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see that the first column is the column of user IDs, I have the movie ID, I have rating and I have a timestamp. Since timestamp will not be used by my recommendation engine, I am dropping this. And also I am renaming my column because surprise expects my column to have these names only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1    31     2.5\n",
       "1     1  1029     3.0\n",
       "2     1  1061     3.0\n",
       "3     1  1129     2.0\n",
       "4     1  1172     4.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will define a reader object. I will tell that the first column is the column of user IDs, the second column is the column of item IDs and ratings and the ratings are on the scale of 1 to 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user, item, rating on scale of 1 to 5\n",
    "reader=surprise.dataset.Reader(line_format='user item rating', rating_scale=(1,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am reading the full dataset from the dataframe mr that I had read in here based on the reader object that I have created here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_train=surprise.dataset.Dataset.load_from_df(mr,reader=reader)\n",
    "mr_trainset=mr_train.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now once this line of code is executed I will create an object called mr_train. This will have all the data that I’ll need to build a recommendation engine. \n",
    "\n",
    "After I create this object, I will have to create a training set object using this method called build_full trainset. Now we are doing all of these steps because surprise expects all of these steps to be done for it to build recommendation engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s use this training set that we have created to build some collaborative filtering models both user based and item based. \n",
    "\n",
    "Now within surprise you have a prediction algorithm module, within the prediction algorithm module, you have various prediction algorithms and some of the algorithms are based on the neighborhood approach. \n",
    "\n",
    "So I am importing the module which contains libraries that are based on neighborhood approach and within this we have a KNNBasic which implements the very basic collaborative filtering model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a neighbourhood based user and item based collaborative filtering model\n",
    "import surprise.prediction_algorithms.knns as knns\n",
    "knnbasic=knns.KNNBasic(k=40,min_k=1,sims_options={'name':'cosine','user_based':True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the k stands for the number of neighbors that I would consider for the closeness of a user or an item. \n",
    "\n",
    "Then I have this parameter called similarity options and herein I am saying that I will be using cosine similarity and this will be a user based collaborative filtering model. \n",
    "\n",
    "So I’ll instantiate an object of KNNBasic class and then I will use the fit method to work on my train dataset that I created to build a user based collaborative filtering model based on the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1e22d7c2ac8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnbasic.fit(mr_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now once it is done creating the model, let me go back to my original dataframe and take a look at some of the data points in that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1    31     2.5\n",
       "1     1  1029     3.0\n",
       "2     1  1061     3.0\n",
       "3     1  1129     2.0\n",
       "4     1  1172     4.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now once this model is trained I can use it to predict the rating for a certain user or for a certain item ID. \n",
    "\n",
    "Now I will be making a rating prediction for user ID 1, for item ID 31 and I also know that the actual rating here is 2.5 which is what I have written in the predict function. Let’s run this. \n",
    "\n",
    "So the predicted rating comes out to be 2.99. And if you think about it, it’s not very far away from what the actual rating was. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=31, r_ui=2.5, est=2.986320319817485, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnbasic.predict(uid=1,iid=31,r_ui=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets’ build an item based collaborative filtering model. \n",
    "\n",
    "Now I’ll still work with the KNNBasic method. I will be using 40 neighbors to predict the rating. The only thing that will change is to the user based parameter I need to provide a value of FALSE for me to build an item based collaborative filtering model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets build an item based collaborative filter\n",
    "knnbasic=knns.KNNBasic(k=40,min_k=1,sims_options={'name':'cosine','user_based':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1e22d7c2c88>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnbasic.fit(mr_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me run this and let me train this and now let me do a prediction for user ID 1, for item 31 based on item based collaborative filtering. Now my estimated rating is 2.99 very similar to what I computed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=31, r_ui=None, est=2.986320319817485, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnbasic.predict(uid=1,iid=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also build collaborative filtering models taking into account the average ratings of users and items. \n",
    "\n",
    "For that I will be using the KNNWithMeans method. Here I am building an item based model because I have given a value of False to the user based parameter. Let me fit this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x1e22d841470>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Collaborative filter with average effects\n",
    "knnbasic=knns.KNNWithMeans(k=40,min_k=1,sims_options={'name':'pearson','user_based':False})\n",
    "knnbasic.fit(mr_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s make a prediction for user ID 1 and item ID 31. Now you can see that the predicted rating is 2.1. The actual rating was 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=31, r_ui=None, est=2.1033560498894315, details={'actual_k': 40, 'was_impossible': False})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knnbasic.predict(uid=1,iid=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now another thing that I can do which is made possible by this framework that I am using, I can split my total data into three folds and I can get an estimate of model performance. \n",
    "\n",
    "So what will happen is I will train my data on two folds and test on one fold. \n",
    "\n",
    "For that I will instantiate an object of the KFold class within the model_selection module of surprise. \n",
    "\n",
    "Then I will run a for loop for every combination of trainset and testset to evaluate the predictions of my KNNBasic algorithm on three folds. Let me run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9814\n",
      "MAE:  0.7548\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9780\n",
      "MAE:  0.7525\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9784\n",
      "MAE:  0.7521\n"
     ]
    }
   ],
   "source": [
    "## Instead of  using just one train set, we can split the data into parts\n",
    "# and then evaluate the model performance out of sample\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "\n",
    "knnbasic=knns.KNNBasic(k=40,sims_options={'name':'cosine','user_based':False})\n",
    "\n",
    "for trainset, testset in kf.split(mr_train):\n",
    "    knnbasic.fit(trainset)\n",
    "    predictions = knnbasic.test(testset)\n",
    "    \n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "    accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as you see above this trains model on two folds and tests on one fold, then trains on the other two fold and tests on one fold, trains on the other two fold and tests on the one fold. \n",
    "\n",
    "So this gives us an idea of the out of sample performance of this model which here is being measured by Root Mean Squared Error and Mean Absolute Error. \n",
    "\n",
    "\n",
    "Now I can repeat the same process with the model which takes into account the average effects. I can evaluate this model on three folds out of sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9215\n",
      "MAE:  0.7059\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9257\n",
      "MAE:  0.7074\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.9324\n",
      "MAE:  0.7143\n"
     ]
    }
   ],
   "source": [
    "## Build a collaborative filter model with average effects\n",
    "# surprise.evaluate(knns.KNNWithMeans(k=40,sims_options={'name':'cosine','user_based':False}),mr_train)\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "\n",
    "knnwithmeans=knns.KNNWithMeans(k=40,sims_options={'name':'cosine','user_based':False})\n",
    "\n",
    "for trainset, testset in kf.split(mr_train):\n",
    "    knnwithmeans.fit(trainset)\n",
    "    predictions = knnwithmeans.test(testset)\n",
    "    \n",
    "    accuracy.rmse(predictions, verbose=True)\n",
    "    accuracy.mae(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now if I compare the accuracy of a model which takes into account means and the model which doesn’t, it seems like the model which takes into account the mean effects is slightly more accurate compared to the model which doesn’t.\n",
    "\n",
    "\n",
    "\n",
    "Now let’s see how we can do grid search. \n",
    "\n",
    "For this to work we’ll first define a grid. Now for a simple demo, I am defining a grid that takes into account the number of neighbors. I will be iterating over 10 neighbors or 20 neighbors. \n",
    "\n",
    "And within the similarity options I will be searching between the cosine similarity and the msd and I will only be building an item based collaborative filtering model. So this is my parameter grid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doing Grid Search\n",
    "param_grid = {'k': [10, 20],\n",
    "              'sim_options': {'name': ['msd', 'cosine'],\n",
    "                              'user_based': [False]}\n",
    "              }\n",
    "## MSD: Mean Squared Difference similarity between all pairs of users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will have to define an estimator first which is what I am doing here and then the surprise module has a GridSearch method to which I will supply the algorithm and the parameter grid and the accuracy measures that I want to do this grid search for me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo=knns.KNNWithMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search = surprise.GridSearchCV(algo,param_grid=param_grid, measures=['RMSE', 'MAE'])\n",
    "\n",
    "grid_search = GridSearchCV(algo,param_grid=param_grid, measures=['RMSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(mr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now doing this grid search will take some time as we have many permutations and combinations that this algorithm will go through. \n",
    "\n",
    "Now once this grid search procedure is run, we can check what were the best parameters based on the RMSE and MAE as a metric or what were the best parameters based on the RMSE and MAE as a metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 20, 'sim_options': {'name': 'msd', 'user_based': False}}\n",
      "{'k': 20, 'sim_options': {'name': 'msd', 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params['rmse'])\n",
    "print(grid_search.best_params['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it turns out that for both, the parameters were similar, it turns out that after we do grid search, a model with 20 neighbors which is a item based model and uses msd as similarity metric is the best model.\n",
    "\n",
    "Also look at best scores for RMSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9243719812746256\n",
      "0.7089037329981174\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_score['rmse'])\n",
    "print(grid_search.best_score['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create this model once again. And using this model, we will see how we can extract top 5 recommendations for a given item. \n",
    "\n",
    "So I will be again building this model based on my grid search results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x1e22d841208>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Top 5 recommendations for an item\n",
    "model=knns.KNNWithMeans(k=20,sim_options={'name': 'msd', 'user_based': False})\n",
    "model.fit(mr_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s take a look at our raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1    31     2.5\n",
       "1     1  1029     3.0\n",
       "2     1  1061     3.0\n",
       "3     1  1129     2.0\n",
       "4     1  1172     4.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to obtain the top 5 recommendations for a given item we will need to do a bit of work. \n",
    "\n",
    "Now what happens is surprise assigns a unique integer ID to each item that it stores as an item set. Now that unique item ID can be recovered using this method called to_inner id. Let’s say I want to understand what is the integer ID that surprise has given to the item whose actual ID is 1061. And it turns out that it has given it an integer ID of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_trainset.to_inner_iid(1061)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this method called model.getneighbors and what we need to do is we will need to provide the inner IDs or the IDs given by the surprise module to a given item ID to find the most similar IDs corresponding to this particular item. \n",
    "\n",
    "So let’s say I want to look at the 5 most similar items. Now this is returning the internal ID of the most 5 similar items to the item whose internal ID is 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51, 80, 95, 269, 292]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_neighbors(mr_trainset.to_inner_iid(1061),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see what would be the raw IDs which are the IDs in my dataset of these items. For that I will run a loop and I will use this method called to_raw_iid. And it turns out that these are the items that are most similar to item number 1061."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "537\n",
      "720\n",
      "2348\n",
      "2867\n"
     ]
    }
   ],
   "source": [
    "for i in [51, 80, 95, 269, 292]:\n",
    "   print(mr_trainset.to_raw_iid(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can similarly also create top 5 predictions for a user. For that I will create a user based collaborative filtering model first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x1e22d841400>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Top 5 recommendations for a user\n",
    "model=knns.KNNWithMeans(k=20,sim_options={'name': 'msd', 'user_based': True})\n",
    "model.fit(mr_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1    31     2.5\n",
       "1     1  1029     3.0\n",
       "2     1  1061     3.0\n",
       "3     1  1129     2.0\n",
       "4     1  1172     4.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a look at the head of the data again. Let’s say for the user 1, I need to find out the most similar users. So first I will get the inner ID of this user. I will use the inner ID of this user to predict the inner IDs of the user similar to user 1. \n",
    "\n",
    "Let’s see what do we get. So users whose inner ID is 8, 32, 67, 95 and 98 are most similar to user whose raw ID is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 32, 67, 95, 98]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mr_trainset.to_inner_uid(1)\n",
    "model.get_neighbors(mr_trainset.to_inner_uid(1),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s convert these inner IDs into raw IDs using this for loop. So users who have a label of 9, 33, 68, 96 and 99 in our data are more similar to user 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "33\n",
      "68\n",
      "96\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for i in [8, 32, 67, 95, 98]:\n",
    "    print(mr_trainset.to_raw_uid(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
